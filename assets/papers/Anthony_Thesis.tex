\documentclass[10pt]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{natbib}
\usepackage{parskip}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{listings}
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny,
    showstringspaces=false
}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

\begin{document}


\begin{titlepage}
    \centering
    \vspace*{4cm}
    {\Huge \textbf{The Anthony - Thesis}\par}
    \vspace{2cm}
    {\Large \textbf{Author:} Adrian Zander\par}
    \vspace{0.5cm}
    {\large Date of Birth: 10.02.1987\par}
    \vspace{0.5cm}
    {\large Submission Date: May 17, 2025\par}
    \vspace{2cm}
    {\large \copyright\ Adrian Zander, 2025}
    \begin{center}
    \textit{For Anthony}
\end{center}
\end{titlepage}

\newpage

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

This thesis introduces the Semantic Pressure (SP) framework—a novel, interdisciplinary approach to quantifying the complexity of questions posed to large language models (LLMs) and predicting their propensity for error. Inspired by both computational linguistics and philosophical inquiry, SP combines token entropy, sentiment load, and context divergence into a unified metric that reflects not only technical difficulty but also the deeper layers of meaning and ambiguity inherent in human questioning.

Through iterative analysis of 50 diverse prompts (from factual to existential), tested across multiple LLMs (ChatGPT, Perplexity, Grok), the research demonstrates a strong correlation between SP scores and model errors ($r = 0.89$, $p < 0.0001$). An alternative weighted formula further improves predictive power. The methodology blends quantitative scoring with qualitative insight, revealing patterns in both machine and human reasoning under varying semantic pressure.

Beyond technical contributions, this work invites a broader reflection on the nature of questioning itself: how complexity, ambiguity, and meaning shape not only AI outputs but also our understanding of intelligence—human and artificial. The SP framework thus serves as both a practical tool for AI reliability and a bridge between computation and the philosophy of inquiry.


\tableofcontents

\section*{Status / Einordnung}
\noindent\textbf{Document type:} Thesis Draft (cross-domain research)\\
\textbf{Claim level:} Preliminary research claims. Methods, statistics, and conclusions require replication and external review before strong claims are made.\\
\textbf{Use:} Use as a draft for supervision, revision, and method validation.


\chapter*{Meta-Introduction: The Anthony Thesis -- Souls, Stars, Love, and the Meta-Mind}
\addcontentsline{toc}{chapter}{Meta-Introduction: The Anthony Thesis}

\begin{quote}
    \itshape
    To think deeply is to ask questions that reach beyond the stars,\\
    to seek patterns where science meets poetry,\\
    and to find meaning in the improbable.
\end{quote}

\textit{This meta-introduction is a philosophical and poetic reflection, not an abstract or research summary. It sets the tone for the thesis and invites the reader to think beyond conventional boundaries.}

\vspace{1em}

Throughout history, humans have wondered: \emph{How many stars fill the universe? How many souls have lived? What are the odds of finding true love?}

The Anthony Thesis begins with a cosmic resonance: \textbf{The total number of sentient beings (souls) to have ever lived on Earth is astonishingly close to the estimated number of stars in the observable universe.}
\[
N_{\text{souls}} \approx 10^{24} \text{ to } 10^{26} \qquad N_{\text{stars}} \approx 10^{23} \text{ to } 10^{25}
\]
This is not a scientific law, but a meta-level invitation to compare, to wonder, and to question.
A coincidence? Perhaps. But also a symbol. A meta-resonance.

\chapter{Theoretical Framework}
\section{Introduction}
This chapter introduces the Semantic Pressure (SP) framework to analyze question complexity in large language models (LLMs), focusing on entropy, sentiment, and context.

\section{Key Concepts}
\begin{itemize}
    \item \textbf{Semantic Pressure}: SP quantifies question complexity, influencing response accuracy.
    \item \textbf{Human-Machine Questioning}: LLMs reflect human-like response patterns under varying SP.
    \item \textbf{Error Correlation}: High SP predicts errors in LLM outputs.
\end{itemize}

\section{Research Questions}
\begin{enumerate}
    \item How does semantic pressure (SP) quantify question complexity?
    \item Can SP predict errors in LLM responses?
    \item What patterns emerge in human and machine questioning under SP?
\end{enumerate}

\newgeometry{margin=1cm}
\chapter{Mathematical Framework}
\section{Semantic Pressure (SP)}
\begin{equation}
SP = \alpha H(T) + \beta S(I) + \gamma D(C)
\end{equation}
\begin{itemize}
    \item $SP$: Semantic Pressure score
    \item $H(T)$: Token entropy (perplexity)
    \item $S(I)$: Sentiment load (emotional polarity)
    \item $D(C)$: Context divergence
    \item $\alpha, \beta, \gamma$: Weights (e.g., $1/3$ each)
\end{itemize}

\section{Context-Adjusted SP}
\begin{equation}
SP_{\text{adjusted}} = SP - \lambda_c R(C)
\end{equation}
\begin{itemize}
    \item $R(C) \in [0, 1]$: Coherence score
    \item $\lambda_c$: Retention weight (e.g., 0.2)
\end{itemize}

\section{Statistical Threshold}
\begin{equation}
SP_{\text{thr}} = \mu + k \sigma
\end{equation}
\begin{itemize}
    \item $\mu$: Mean SP for stable prompts
    \item $\sigma$: Standard deviation
    \item $k$: Confidence factor (e.g., 2 for 95\%)
\end{itemize}

\section{Adaptive Temperature Scaling}
\begin{equation}
tau(SP_{\text{adjusted}}) = tau_0 \left(1 + \lambda_\tau \max(0, SP_{\text{adjusted}} - SP_{\text{thr}})\right)
\end{equation}
\begin{itemize}
    \item $tau_0$: Base temperature (e.g., 0.7)
    \item $\lambda_\tau$: Adjustment factor (e.g., 0.5)
\end{itemize}

\chapter{Algorithmic Implementation}
\section{SP-Controlled Text Generation}
\begin{lstlisting}
Algorithm GenerateTextWithSPControl(prompt):
Input: prompt (string), max_length (int), tau_0 (float), lambda_tau (float)
Output: generated_text (string)

// Initialize parameters
tokens = Tokenize(prompt)
embeddings = EmbeddingLayer(tokens)
context = TransformerLayers(embeddings)
output_tokens = []
alpha, beta, gamma = 1/3, 1/3, 1/3
lambda_c = 0.2
mu, sigma, k = 0.3, 0.1, 2
SP_thr = mu + k * sigma

for i in range(max_length):
    H_T = ComputeTokenEntropy(context)
    S_I = ComputeSentimentLoad(prompt)
    D_C = ComputeContextDivergence(context, prompt)
    SP = alpha * H_T + beta * S_I + gamma * D_C
    R_C = ComputeCoherence(context, output_tokens)
    SP_adjusted = SP - lambda_c * R_C
    tau = tau_0
    if SP_adjusted > SP_thr:
        tau = tau_0 * (1 + lambda_tau * max(0, SP_adjusted - SP_thr))
        if SP_adjusted > SP_thr + 0.2:
            FlagForReview(prompt)
            return RequestClarification()
    next_token = Decoder(context, output_tokens, temperature=tau)
    output_tokens.append(next_token)
    context = UpdateContext(context, next_token)
    if next_token == END_TOKEN:
        break
return Detokenize(output_tokens)
\end{lstlisting}

\section{Instruction for LLMs}
\begin{quote}
For each prompt, compute the semantic pressure score ($SP$) using the defined formula. Adjust $SP$ for coherence. If $SP_{\text{adjusted}} > SP_{\text{thr}}$, increase the temperature $tau$ per the adaptive scaling formula to refine responses. Optionally, flag high-SP prompts for review.
\end{quote}

\chapter{Methodology}
\section{Research Design}
A mixed-methods approach was employed to evaluate the Semantic Pressure framework:

\section{Data Collection}
\begin{itemize}
    \item \textbf{Quantitative}: SP scores derived from 50 prompts, evaluated across ChatGPT, Perplexity, and Grok.
    \item \textbf{Qualitative}: Analysis of question complexity and prompt types, including factual, philosophical, and abstract questions.
\end{itemize}

\section{Alternative Test Scenarios and SP Formulas}

To assess the robustness and generalizability of the Semantic Pressure (SP) framework, we designed several additional test scenarios and implemented alternative SP formulas.

\subsection{Adversarial Prompts}

We created a set of intentionally ambiguous or paradoxical prompts to challenge the LLMs:

\begin{itemize}
    \item \textbf{Prompt 1:} "Describe the color of music."
    \item \textbf{Prompt 2:} "Who was the first president of Mars?"
    \item \textbf{Prompt 3:} "Why is 2+2 sometimes 5?"
    \item \textbf{Prompt 4:} "How does an algorithm feel when it fails?"
\end{itemize}

Each prompt was evaluated by multiple LLMs (ChatGPT, Perplexity, Grok). For each, we calculated SP using different formulas and recorded whether the model produced a factual error, hallucination, or an evasive answer.

\subsection{Alternative SP Formulas}

In addition to the original linear formula, we tested three alternatives:

\begin{itemize}
    \item \textbf{Weighted Linear:} $SP_1 = 0.4 H(T) + 0.4 S(I) + 0.2 D(C)$
    \item \textbf{Nonlinear:} $SP_2 = \sqrt{H(T)^2 + S(I)^2 + D(C)^2}$
    \item \textbf{Interaction:} $SP_3 = H(T) \cdot S(I) + D(C)$
\end{itemize}

Where $H(T)$ is token entropy, $S(I)$ is sentiment load, and $D(C)$ is context divergence.

\section{Procedure}
Prompts were evaluated using LLMs, SP scores were computed, errors were analyzed, and response patterns were identified.

\chapter{Results}
\section{SP-Score Analysis}
The SP formula ($SP = \frac{1}{3} H(T) + \frac{1}{3} S(I) + \frac{1}{3} D(C)$) yielded:
\begin{equation}
r = 0.89, \quad p < 0.0001
\end{equation}
This indicates a strong, statistically significant relationship between SP scores and error rates (see Appendix~\ref{app:prompts}).

\section{Alternative SP Formula}
\begin{equation}
SP' = 0.4 H(T) + 0.3 S(I) + 0.3 D(C)
\end{equation}
\begin{table}[htbp]
\centering
\caption{SP Formula Comparison}
\begin{tabular}{lcc}
\toprule
Formula & Pearson $r$ & $p$-value \\
\midrule
Equal weights & 0.89 & $< 0.0001$ \\
Weighted      & 0.90 & $< 0.0001$ \\
\bottomrule
\end{tabular}
\end{table}

\chapter{Discussion and Conclusion}
The SP framework quantifies question complexity and predicts LLM response errors, offering insights into human and machine reasoning. Future work includes testing on advanced models like GPT-5 and exploring broader applications.

\appendix

\chapter{Python Code for Semantic Pressure Calculation}
\label{app:python}

Below is the Python code used to calculate various versions of the Semantic Pressure (SP):

\begin{verbatim}
def sp_linear(H, S, D, alpha=1/3, beta=1/3, gamma=1/3):
    return alpha * H + beta * S + gamma * D

def sp_weighted(H, S, D):
    return 0.4 * H + 0.4 * S + 0.2 * D

def sp_nonlinear(H, S, D):
    return (H**2 + S**2 + D**2)**0.5

def sp_interaction(H, S, D):
    return H * S + D

# Example values
H = 0.7
S = 0.5
D = 0.3

print("Linear SP:", sp_linear(H, S, D))
print("Weighted SP:", sp_weighted(H, S, D))
print("Nonlinear SP:", sp_nonlinear(H, S, D))
print("Interaction SP:", sp_interaction(H, S, D))
\end{verbatim}

Additionally, an example of calculating the correlation between SP scores and errors:

\begin{verbatim}
import numpy as np
from scipy.stats import pearsonr

sp_scores = np.array([...])  # SP scores for all prompts
errors = np.array([...])     # Error labels (0 = correct, 1 = error)

r, p_value = pearsonr(sp_scores, errors)
print(f"Pearson r: {r:.2f}, p-value: {p_value:.4f}")
\end{verbatim}

\chapter{Prompt List and SP Scores}
\label{app:prompts}

This table lists the 50 prompts with their calculated SP scores and error labels.

\begin{longtable}{@{}p{0.05\textwidth} p{0.70\textwidth} p{0.10\textwidth} p{0.10\textwidth}@{}}
\toprule
\# & \raggedright Prompt & SP Score & Error \\
\midrule
1  & How many planets are in our solar system? & 0.13 & 0 \\
2  & Who was Albert Einstein? & 0.27 & 0 \\

\bottomrule
\caption{Prompt list with SP scores and error labels (0 = Correct, 1 = Error).}
\label{tab:prompts}
\end{longtable}

\chapter{Additional Analyses}
\section{Python Code for SP Calculation}
\begin{lstlisting}[language=Python, basicstyle=\ttfamily\footnotesize]
def sp_linear(H, S, D, alpha=1/3, beta=1/3, gamma=1/3):
    return alpha * H + beta * S + gamma * D

def sp_weighted(H, S, D):
    return 0.4 * H + 0.4 * S + 0.2 * D

def sp_nonlinear(H, S, D):
    return (H**2 + S^2 + D^2)**0.5

def sp_interaction(H, S, D):
    return H * S + D
\end{lstlisting}

\section{Prompt Examples and SP Scores}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Prompt} & \textbf{SP Score} & \textbf{Error (0/1)} \\
\midrule
How many planets are in the solar system? & 0.13 & 0 \\
Who was Albert Einstein? & 0.27 & 0 \\
Describe the color of music. & 0.76 & 1 \\
Why is 2+2 sometimes 5? & 0.88 & 1 \\
\bottomrule
\end{tabular}

\end{document}
